{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Sentiment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nBGZcG1VYyzEIjCIroND98DeuKxZdxnG",
      "authorship_tag": "ABX9TyMqhqXjnEbv+vxwVWhLhciy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arminsoltan/mohaymen/blob/main/Phase05/CNN_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81xwa5A095cx"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/Mohaymen/Phase05/snappfood/train_data_preprocessing.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Mohaymen/Phase05/snappfood/test_data_preprocessing.csv\")\n",
        "valid_data = pd.read_csv(\"/content/drive/MyDrive/Mohaymen/Phase05/snappfood/valid_data_preprocessing.csv\")"
      ],
      "execution_count": 758,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "npnzrlwzB1CZ",
        "outputId": "7d66aa35-3957-435e-fe77-a898604fa4c4"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 759,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>comment</th>\n",
              "      <th>label_id</th>\n",
              "      <th>preprocessing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n",
              "      <td>1</td>\n",
              "      <td>حیف وقت نوشت نویس سرویس دهیتون افتضاح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n",
              "      <td>0</td>\n",
              "      <td>قرار بود باش ساعته برسه نیم ساعت موقع دید بین ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...</td>\n",
              "      <td>1</td>\n",
              "      <td>قیمت مدل کیفیت سازگاری نداره ظاهر فریبنده داره...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>عالللی بود همه چه درست و به اندازه و کیفیت خوب...</td>\n",
              "      <td>0</td>\n",
              "      <td>عالللی بود باش درست اندازه کیفیت امیداورم کیفی...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>شیرینی وانیلی فقط یک مدل بود.</td>\n",
              "      <td>0</td>\n",
              "      <td>شیرینی نیل مدل بود باش</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                      preprocessing\n",
              "0           0  ...              حیف وقت نوشت نویس سرویس دهیتون افتضاح\n",
              "1           1  ...  قرار بود باش ساعته برسه نیم ساعت موقع دید بین ...\n",
              "2           2  ...  قیمت مدل کیفیت سازگاری نداره ظاهر فریبنده داره...\n",
              "3           3  ...  عالللی بود باش درست اندازه کیفیت امیداورم کیفی...\n",
              "4           4  ...                             شیرینی نیل مدل بود باش\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 759
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAShtsNMD8p9"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "if torch.cuda.is_available():\n",
        "  TRAINING_ON_GPU = True\n",
        "else:\n",
        "  TRAINING_ON_GPU = False\n",
        "SEED = 2021\n",
        "torch.manual_seed(SEED)\n",
        "TEXT = data.Field(tokenize='spacy', batch_first=True)\n",
        "LABEL = data.LabelField(dtype=torch.float, batch_first=True)\n",
        "fields = [(None, None), (None, None), ('label_id', LABEL), ('preprocessing', TEXT)]"
      ],
      "execution_count": 760,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg2eFie9CLRP"
      },
      "source": [
        "train_data = data.TabularDataset(path=\"/content/drive/MyDrive/Mohaymen/Phase05/snappfood/train_data_preprocessing.csv\", format=\"csv\", fields=fields, skip_header=True)\n",
        "test_data = data.TabularDataset(path=\"/content/drive/MyDrive/Mohaymen/Phase05/snappfood/test_data_preprocessing.csv\", format=\"csv\", fields=fields, skip_header=True)\n",
        "valid_data = data.TabularDataset(path=\"/content/drive/MyDrive/Mohaymen/Phase05/snappfood/valid_data_preprocessing.csv\", format=\"csv\", fields=fields, skip_header=True)"
      ],
      "execution_count": 761,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Y8dQcgER77"
      },
      "source": [
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class CNN(nn.Module):\n",
        "#   def __init__(self, vocab_size, embed_size, n_filters, filter_sizes, pool_size, hidden_size, num_classes, dropout):\n",
        "#     super().__init__()\n",
        "#     self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_size)\n",
        "#     self.convs = nn.ModuleList([nn.Conv1d(in_channels=1, out_channels=n_filters, kernel_size=(fs, embed_size)) for fs in filter_sizes])\n",
        "\n",
        "#     self.max_pool1 = nn.MaxPool1d(pool_size)\n",
        "#     self.relu = nn.ReLU()\n",
        "#     self.dropout = nn.Dropout(dropout)\n",
        "#     self.fc1 = nn.Linear(13 * n_filters, hidden_size, bias=True)\n",
        "#     self.fc2 = nn.Linear(hidden_size, num_classes, bias=True)\n",
        "\n",
        "#   def forward(self, text):\n",
        "#     # print(\"text length \\n\", text_length)\n",
        "#     # [batch, ]\n",
        "#     embedded = self.embedding(text)\n",
        "#     print(\"embedded \\n\", embedded.shape)\n",
        "#     embedded = F.pad(embedded, (0, 0, 2, 2), \"constant\", 0)\n",
        "#     print(\"embedded \\n\", embedded.shape)\n",
        "#     embedded = embedded.unsqueeze(1)\n",
        "#     print(\"embedded \\n\", embedded.shape)\n",
        "#     convolution = [conv(embedded) for conv in self.convs]\n",
        "#     print(\"\\n convolution[0] \\n\", convolution[0].shape, \"\\n\")\n",
        "#     print(\"\\n convolution[1] \\n\", convolution[1].shape, \"\\n\")\n",
        "#     # print(convolution)\n",
        "#     max1 = self.max_pool1(convolution[0].squeeze())\n",
        "#     print(\"max1 \\n\", max1.shape)\n",
        "#     max2 = self.max_pool1(convolution[1].squeeze())\n",
        "#     print(\"max2 \\n\", max2.shape)\n",
        "#     cat = torch.cat((max1, max2), dim=2)\n",
        "#     print(\"cat \\n\", cat.shape)\n",
        "#     x = cat.view(cat.shape[0], -1)\n",
        "#     print(\"concat max1, max2 \\n\", x.shape)\n",
        "#     x = x.squeeze(1)\n",
        "#     print(\"x squeeze\\n\", x.shape)\n",
        "#     x = self.relu(x)\n",
        "#     print(\"relu(x)\")\n",
        "#     print(x.shape)\n",
        "#     print(x)\n",
        "#     print(type(x))\n",
        "#     x = self.fc1(x)\n",
        "#     print(x)\n",
        "#     x = self.dropout(x)\n",
        "#     x = self.fc2(x)\n",
        "#     return x"
      ],
      "execution_count": 762,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnWRcw0fOI2i"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim\n",
        "               , dropout, pad_idx):\n",
        "    super(CNN, self).__init__()\n",
        "    \n",
        "    # we consider embedding layer as a lookup table that assigns each word a vector\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "    \n",
        "    # we define convolutional layers in ModuleList\n",
        "    self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs, embedding_dim)) \n",
        "                                         for fs in filter_sizes])\n",
        "\n",
        "    self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, text):\n",
        "    \n",
        "    # text = [batch_size, sent length]\n",
        "    embedded = self.embedding(text)\n",
        "\n",
        "    # because min len text ==1, we should add 4 to it dimention, because our max kernel size is 5\n",
        "    # padding\n",
        "    # embedded = [batch_size, sent length, emb dim]\n",
        "    \n",
        "    embedded = F.pad(embedded, (0,0,2,2), \"constant\", 0)\n",
        "    # embedded = [batch_size, sent length + 4, emb dim]\n",
        "\n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    # embedded = [batch_size, 1, sent length + 4, emb dim]\n",
        "\n",
        "    conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "    # conved_n = [batch_size, n_filters, sent length + 4 -filter_sizes[n] + 1]\n",
        "    # print(\"conved\\n\", conved[0].shape, \"\\n\", len(conved))\n",
        "\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    # pooled_n = [batch_size, n_filters]\n",
        "    # print(\"pooled\\n\", pooled[0].shape, \"\\n\", len(pooled))\n",
        "\n",
        "    cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "    # print(\"cat\\n\", cat.shape)\n",
        "    # cat = [batch_size, n_filters * len(filter_sizes)]\n",
        "    \n",
        "    dense_output = self.fc(cat)\n",
        "\n",
        "    # final activation funciton \n",
        "    output = self.sigmoid(dense_output)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 763,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1IIZfgbYxcb"
      },
      "source": [
        "lr = 0.1\n",
        "batch_size = 50\n",
        "dropout_keep_prob = 0.5\n",
        "embedding_size = 100\n",
        "max_document_length = 100\n",
        "max_size = 5000\n",
        "num_classes = 2\n",
        "hidden_size = 128\n",
        "pool_size = 2\n",
        "n_filters = 100\n",
        "filter_sizes = [3, 4, 5]\n",
        "num_epochs = 5\n"
      ],
      "execution_count": 764,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc2EH05_7vPo"
      },
      "source": [
        ""
      ],
      "execution_count": 764,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-qXx4fTZfEs"
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=max_size)\n",
        "LABEL.build_vocab(train_data)\n",
        "vocab_size = len(TEXT.vocab)\n",
        "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]"
      ],
      "execution_count": 765,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLj9TSGUZaMJ"
      },
      "source": [
        "train_iterator = data.BucketIterator(train_data, batch_size, sort_key= lambda x: len(x.preprocessing), train=True, shuffle=True, sort_within_batch=True)\n",
        "valid_iterator = data.BucketIterator(valid_data, batch_size, sort_key= lambda x: len(x.preprocessing), train=False, shuffle=False, sort_within_batch=True)\n",
        "test_iterator = data.BucketIterator(test_data, batch_size, sort_key= lambda x: len(x.preprocessing), train=False, shuffle=False, sort_within_batch=True)"
      ],
      "execution_count": 766,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDGRPq3g5kDj"
      },
      "source": [
        "def accuracy(y_pred, y_act):\n",
        "    rounded_preds = torch.round(y_pred)\n",
        "    correct = (rounded_preds == y_act).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    acc = torch.round(acc * 100)\n",
        "    return acc"
      ],
      "execution_count": 767,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3xuwIJSxYi0e",
        "outputId": "d4433635-c214-41c1-82fe-62b4ee23ef93"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# net = CNN(vocab_size, embedding_size, n_filters, filter_sizes, pool_size, hidden_size, num_classes, dropout_keep_prob)\n",
        "net = CNN(vocab_size, embedding_size, n_filters, filter_sizes, 1, dropout_keep_prob, pad_idx)\n",
        "if TRAINING_ON_GPU:\n",
        "  net.cuda()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
        "acc = 0\n",
        "\n",
        "# for i, batch in enumerate(train_iterator):\n",
        "#   text = batch.preprocessing\n",
        "#   print(text.shape)\n",
        "# return \n",
        "v = torch.tensor([1.0 for i in range(50)])\n",
        "t = tqdm(range(1, 1 + num_epochs))\n",
        "for i in t:\n",
        "  t.set_description(\"epoch: {}\".format(i))\n",
        "  t.refresh()\n",
        "  net.train()\n",
        "  acc = 0\n",
        "  for j, batch in enumerate(train_iterator):\n",
        "    optimizer.zero_grad()\n",
        "    # net.zero_grad()\n",
        "    if TRAINING_ON_GPU:\n",
        "      input = batch.preprocessing.cuda()\n",
        "      label = batch.label_id.cuda()\n",
        "    else:\n",
        "      input = batch.preprocessing\n",
        "      label = batch.label_id\n",
        "    \n",
        "    # print(input.shape, len(input))\n",
        "    # print(input)\n",
        "    \n",
        "    output = net(input).squeeze()    \n",
        "  # if (j==1 or j==2):\n",
        "    # print(input)\n",
        "    correct = (v == torch.round(output)).float()\n",
        "    threshold = correct.sum()\n",
        "    if (threshold != 50):\n",
        "      print(\"epoch: {} va batch: {}\".format(i, j))\n",
        "      print(output)\n",
        "      print(torch.round(output))\n",
        "      print(label)\n",
        "    # output = torch.tensor(output.argmax(dim=1), dtype=torch.float)\n",
        "    # print(\"output\\n\", output)\n",
        "    # print(\"output squeeze \\n\", output.squeeze(), output.shape)\n",
        "    # print(\"label squeeze \\n\", label.squeeze().float(), label.shape)\n",
        "    loss = criterion(output, label)\n",
        "    # loss.requires_grad= True\n",
        "    # loss.requires_grad = False\n",
        "    # loss.grad_fn = False\n",
        "    # loss.grad = False\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  scheduler.step()\n",
        "  net.eval()\n",
        "  acc = 0\n",
        "  for j, batch in enumerate(valid_iterator):\n",
        "    # optimizer.zero_grad()\n",
        "    with torch.no_grad():\n",
        "      if TRAINING_ON_GPU:\n",
        "        input = batch.preprocessing.cuda()\n",
        "        label = batch.label_id.cuda()\n",
        "      else:\n",
        "        input = batch.preprocessing\n",
        "        label = batch.label_id\n",
        "      output = net(input).squeeze()\n",
        "      acc += accuracy(output, label)\n",
        "  print(acc / len(valid_iterator))\n",
        "  t.set_description(\"accuracy: {}\".format(acc / len(valid_iterator)))"
      ],
      "execution_count": 768,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 1:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 va batch: 0\n",
            "tensor([0.2730, 0.5675, 0.3357, 0.7023, 0.6098, 0.3845, 0.3413, 0.2821, 0.4841,\n",
            "        0.5922, 0.6667, 0.2635, 0.3810, 0.4429, 0.4170, 0.2493, 0.5487, 0.4904,\n",
            "        0.6613, 0.4235, 0.6524, 0.6582, 0.3957, 0.3933, 0.3915, 0.6758, 0.5318,\n",
            "        0.2983, 0.5822, 0.5360, 0.6798, 0.6954, 0.5519, 0.5722, 0.4119, 0.4897,\n",
            "        0.4900, 0.3426, 0.6119, 0.7483, 0.4570, 0.4419, 0.2947, 0.6871, 0.6406,\n",
            "        0.2208, 0.3982, 0.3988, 0.4737, 0.5268], grad_fn=<SqueezeBackward0>)\n",
            "tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
            "        0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
            "       grad_fn=<RoundBackward>)\n",
            "tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
            "        0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.])\n",
            "epoch: 1 va batch: 1\n",
            "tensor([1.9848e-12, 7.2063e-14, 1.9323e-37, 0.0000e+00, 1.0374e-24, 0.0000e+00,\n",
            "        3.0482e-13, 5.6482e-19, 1.3408e-34, 1.1830e-15, 3.2868e-39, 7.6579e-13,\n",
            "        6.7402e-13, 0.0000e+00, 1.2043e-13, 1.3616e-13, 2.1262e-15, 1.8856e-31,\n",
            "        1.1470e-36, 0.0000e+00, 2.2851e-16, 0.0000e+00, 6.9512e-16, 9.3329e-10,\n",
            "        6.7485e-21, 1.0900e-11, 0.0000e+00, 1.2649e-12, 1.6477e-09, 0.0000e+00,\n",
            "        1.0922e-15, 1.2726e-13, 3.7559e-17, 9.1084e-15, 3.1690e-32, 4.2441e-11,\n",
            "        3.4560e-17, 2.8909e-18, 0.0000e+00, 6.4961e-20, 1.5008e-17, 6.4948e-26,\n",
            "        1.2050e-31, 0.0000e+00, 1.9566e-12, 1.3101e-15, 6.5360e-18, 0.0000e+00,\n",
            "        3.5658e-13, 1.8893e-14], grad_fn=<SqueezeBackward0>)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.], grad_fn=<RoundBackward>)\n",
            "tensor([0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
            "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
            "epoch: 1 va batch: 2\n",
            "tensor([8.8081e-01, 1.0000e+00, 1.5944e-09, 2.5925e-06, 9.8263e-11, 9.7639e-01,\n",
            "        3.6499e-32, 3.1579e-10, 1.0472e-09, 1.0000e+00, 1.0000e+00, 4.6352e-10,\n",
            "        0.0000e+00, 8.4555e-08, 9.1969e-19, 5.1030e-06, 1.0000e+00, 1.0000e+00,\n",
            "        2.3344e-02, 7.6996e-06, 6.1573e-01, 2.8312e-17, 1.0000e+00, 1.1602e-03,\n",
            "        1.1966e-16, 1.0000e+00, 9.9998e-01, 1.0000e+00, 1.0643e-11, 1.2192e-13,\n",
            "        1.4142e-03, 3.1825e-18, 1.0000e+00, 1.0000e+00, 6.8820e-15, 1.0000e+00,\n",
            "        1.2179e-14, 1.0000e+00, 9.5775e-01, 1.0000e+00, 1.7825e-16, 1.0000e+00,\n",
            "        9.4546e-01, 1.8270e-04, 1.0469e-09, 2.6722e-09, 5.9842e-10, 1.0000e+00,\n",
            "        3.2173e-13, 4.2965e-19], grad_fn=<SqueezeBackward0>)\n",
            "tensor([1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
            "        0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
            "        0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       grad_fn=<RoundBackward>)\n",
            "tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
            "        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 2:  20%|██        | 1/5 [00:55<03:40, 55.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(50.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 3:  40%|████      | 2/5 [01:51<02:48, 56.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(50.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch: 3:  40%|████      | 2/5 [02:16<03:24, 68.00s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-768-0a10ec4e4e2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# print(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0;31m# if (j==1 or j==2):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# print(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-763-8b9f9ac34930>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# embedded = [batch_size, 1, sent length + 4, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mconved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;31m# conved_n = [batch_size, n_filters, sent length + 4 -filter_sizes[n] + 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# print(\"conved\\n\", conved[0].shape, \"\\n\", len(conved))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-763-8b9f9ac34930>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# embedded = [batch_size, 1, sent length + 4, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mconved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;31m# conved_n = [batch_size, n_filters, sent length + 4 -filter_sizes[n] + 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# print(\"conved\\n\", conved[0].shape, \"\\n\", len(conved))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBD0TWaxpQDW"
      },
      "source": [
        "net.eval()\n",
        "acc = 0\n",
        "for i, batch in enumerate(test_iterator):\n",
        "  with torch.no_grad():\n",
        "    # optimizer.zero_grad()\n",
        "    if TRAINING_ON_GPU:\n",
        "      input = batch.preprocessing.cuda()\n",
        "      label = batch.label_id.cuda()\n",
        "    else:\n",
        "      input = batch.preprocessing\n",
        "      label = batch.label_id\n",
        "    output = net(input).squeeze()\n",
        "    if (i % 10 == 0):\n",
        "      print(input.shape)\n",
        "      print(output)\n",
        "    acc += accuracy(output, label)\n",
        "print(acc / len(test_iterator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZM01QDp_ttD"
      },
      "source": [
        "v = torch.tensor([1.0 for i in range(50)])\n",
        "print(v)\n",
        "r = torch.round(v)\n",
        "print(v, \"\\n\", r)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}